{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-03T15:12:17.350081Z","iopub.execute_input":"2022-03-03T15:12:17.350402Z","iopub.status.idle":"2022-03-03T15:12:17.627724Z","shell.execute_reply.started":"2022-03-03T15:12:17.350319Z","shell.execute_reply":"2022-03-03T15:12:17.627031Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"Rebuild_data=True","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:12:20.416574Z","iopub.execute_input":"2022-03-03T15:12:20.417132Z","iopub.status.idle":"2022-03-03T15:12:20.420558Z","shell.execute_reply.started":"2022-03-03T15:12:20.417091Z","shell.execute_reply":"2022-03-03T15:12:20.419882Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class DogsVsCats:\n    img_size=50\n    cats='/kaggle/input/dogs-cats-images/dog vs cat/dataset/training_set/cats/'\n    dogs='/kaggle/input/dogs-cats-images/dog vs cat/dataset/training_set/dogs/'\n    labels={cats:0,dogs:1}\n    training_data=[]\n    catcount=0\n    dogcount=0\n                \n    def make_training_data(self):\n        for label in self.labels:\n            try:\n                for f in tqdm(os.listdir(label)):\n                    path=os.path.join(label,f)\n                    img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n                    img=cv2.resize(img,(self.img_size,self.img_size))\n                    self.training_data.append([np.array(img),np.eye(2)[self.labels[label]]])\n                    \n                    if label == self.cats:\n                        self.catcount+=1\n                    elif label == self.dogs:\n                        self.dogcount+=1\n            except Exception as e:\n                pass  \n            \n        np.random.shuffle(self.training_data)\n        np.save('training_data.npy',self.training_data)\n        print('Cats:',self.catcount)\n        print('Dogs:',self.dogcount)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:12:23.005698Z","iopub.execute_input":"2022-03-03T15:12:23.006088Z","iopub.status.idle":"2022-03-03T15:12:23.096759Z","shell.execute_reply.started":"2022-03-03T15:12:23.006056Z","shell.execute_reply":"2022-03-03T15:12:23.095641Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if Rebuild_data:\n    dogsvcats = DogsVsCats()\n    dogsvcats.make_training_data()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:12:29.655083Z","iopub.execute_input":"2022-03-03T15:12:29.655908Z","iopub.status.idle":"2022-03-03T15:13:45.713213Z","shell.execute_reply.started":"2022-03-03T15:12:29.655857Z","shell.execute_reply":"2022-03-03T15:13:45.712420Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"training_data=np.load('training_data.npy',allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:15:33.866544Z","iopub.execute_input":"2022-03-03T15:15:33.867275Z","iopub.status.idle":"2022-03-03T15:15:33.935274Z","shell.execute_reply.started":"2022-03-03T15:15:33.867234Z","shell.execute_reply":"2022-03-03T15:15:33.934604Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:15:36.216037Z","iopub.execute_input":"2022-03-03T15:15:36.216538Z","iopub.status.idle":"2022-03-03T15:15:36.232943Z","shell.execute_reply.started":"2022-03-03T15:15:36.216500Z","shell.execute_reply":"2022-03-03T15:15:36.231886Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(training_data[0][0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:15:49.113578Z","iopub.execute_input":"2022-03-03T15:15:49.114274Z","iopub.status.idle":"2022-03-03T15:15:49.292056Z","shell.execute_reply.started":"2022-03-03T15:15:49.114235Z","shell.execute_reply":"2022-03-03T15:15:49.291374Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:15:55.361989Z","iopub.execute_input":"2022-03-03T15:15:55.362248Z","iopub.status.idle":"2022-03-03T15:15:56.688022Z","shell.execute_reply.started":"2022-03-03T15:15:55.362218Z","shell.execute_reply":"2022-03-03T15:15:56.687160Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1=nn.Conv2d(1,32,5)     #f=5 - that is the frame window will be of size 5\n        self.conv2=nn.Conv2d(32,64,5)\n        self.conv3=nn.Conv2d(64,128,5)\n        \n        x=torch.randn(50,50).view(-1,1,50,50)\n        self._to_linear=None\n        self.convs(x)\n        \n        self.fc1=nn.Linear(self._to_linear,512)\n        self.fc2=nn.Linear(512,2)\n\n    def convs(self,x):\n        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n        x=F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n        x=F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n        \n        #print(x[0].shape)\n        if self._to_linear is None:\n            self._to_linear=x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n        return x\n    \n    def forward(self,x):\n        x=self.convs(x)\n        x=x.view(-1,self._to_linear)\n        x=F.relu(self.fc1(x))\n        x=self.fc2(x)\n        return F.softmax(x,dim=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:15:59.771828Z","iopub.execute_input":"2022-03-03T15:15:59.772105Z","iopub.status.idle":"2022-03-03T15:15:59.783902Z","shell.execute_reply.started":"2022-03-03T15:15:59.772072Z","shell.execute_reply":"2022-03-03T15:15:59.782967Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"net=Net()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:17:28.334066Z","iopub.execute_input":"2022-03-03T15:17:28.334714Z","iopub.status.idle":"2022-03-03T15:17:28.431334Z","shell.execute_reply.started":"2022-03-03T15:17:28.334655Z","shell.execute_reply":"2022-03-03T15:17:28.430636Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Splitting training data into X and y values and creating a ratio to split the data into train and test\nimport torch.optim as optim\n\noptimizer=optim.Adam(net.parameters(),lr=0.001)\nloss_function=nn.MSELoss()\n\nX=torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\nX=X/255.0\ny=torch.Tensor([i[1] for i in training_data])\n\nval_pct=0.1\nval_size=int(len(X)*val_pct)\nprint(val_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:17:34.187484Z","iopub.execute_input":"2022-03-03T15:17:34.187962Z","iopub.status.idle":"2022-03-03T15:17:38.209236Z","shell.execute_reply.started":"2022-03-03T15:17:34.187922Z","shell.execute_reply":"2022-03-03T15:17:38.208460Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Splitting the data into train and valid set\ntrain_X=X[:-val_size]\ntrain_y=y[:-val_size]\n\nval_x=X[-val_size:]\nval_y=y[-val_size:]\nprint(val_y.shape)\nprint(train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:57:33.306031Z","iopub.execute_input":"2022-03-03T15:57:33.306286Z","iopub.status.idle":"2022-03-03T15:57:33.317474Z","shell.execute_reply.started":"2022-03-03T15:57:33.306257Z","shell.execute_reply":"2022-03-03T15:57:33.316606Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Why do we need to mark the gradient zero while training pytorch model","metadata":{}},{"cell_type":"markdown","source":"In PyTorch, for every mini-batch during the training phase, we typically want to explicitly set the gradients to zero before starting to do backpropragation (i.e., updating the Weights and biases) because PyTorch accumulates the gradients on subsequent backward passes. This accumulating behaviour is convenient while training RNNs or when we want to compute the gradient of the loss summed over multiple mini-batches. So, the default action has been set to accumulate (i.e. sum) the gradients on every loss.backward() call.\n\nBecause of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Otherwise, the gradient would be a combination of the old gradient, which you have already used to update your model parameters, and the newly-computed gradient.","metadata":{}},{"cell_type":"code","source":"#training the model and accounting the loss with CPU\nbatch_size=100\nepoch=1\n\nfor epoch in range(epoch):\n    for i in tqdm(range(0,len(train_X),batch_size)):\n        #print(i,i+batch_size)\n        batch_X=train_X[i:i+batch_size].view(-1,1,50,50)\n        batch_y=train_y[i:i+batch_size]\n        \n        net.zero_grad()    #if we are combining multiple network then we might use optimizer.zero_grad as there will be mulitple optimizer\n        outputs=net(batch_X)\n        loss=loss_function(outputs,batch_y)\n        loss.backward()\n        optimizer.step()\n\nprint(loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:32:17.380102Z","iopub.execute_input":"2022-03-02T15:32:17.380666Z","iopub.status.idle":"2022-03-02T15:32:35.316619Z","shell.execute_reply.started":"2022-03-02T15:32:17.380628Z","shell.execute_reply":"2022-03-02T15:32:35.315904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the accuracy of the model on validation set\ncorrect=0\ntotal=0\n\nwith torch.no_grad():\n    for i in tqdm(range(len(val_x))):\n        real_class=torch.argmax(val_y[i])\n        net_out=net(val_x[i].view(-1,1,50,50))[0]\n        predicted_class=torch.argmax(net_out)\n        if real_class == predicted_class:\n            correct+=1\n        total+=1\n\nprint('Accuracy:',round(correct/total,3))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:34:01.05278Z","iopub.execute_input":"2022-03-02T15:34:01.053048Z","iopub.status.idle":"2022-03-02T15:34:02.371769Z","shell.execute_reply.started":"2022-03-02T15:34:01.053016Z","shell.execute_reply":"2022-03-02T15:34:02.371098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To validate if you are accessing GPU\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:18:53.320043Z","iopub.execute_input":"2022-03-03T15:18:53.320497Z","iopub.status.idle":"2022-03-03T15:18:53.366771Z","shell.execute_reply.started":"2022-03-03T15:18:53.320456Z","shell.execute_reply":"2022-03-03T15:18:53.365747Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Assigning device\ndevice=torch.device('cuda:0')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:18:55.319826Z","iopub.execute_input":"2022-03-03T15:18:55.320286Z","iopub.status.idle":"2022-03-03T15:18:55.326238Z","shell.execute_reply.started":"2022-03-03T15:18:55.320248Z","shell.execute_reply":"2022-03-03T15:18:55.325388Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device('cuda:0')\n    print('Running on GPU')\nelse:\n    device=torch.device('cpu')\n    print('Running on CPU')","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:19:01.454933Z","iopub.execute_input":"2022-03-03T15:19:01.456878Z","iopub.status.idle":"2022-03-03T15:19:01.463658Z","shell.execute_reply.started":"2022-03-03T15:19:01.456826Z","shell.execute_reply":"2022-03-03T15:19:01.462385Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:19:04.699453Z","iopub.execute_input":"2022-03-03T15:19:04.699727Z","iopub.status.idle":"2022-03-03T15:19:04.707553Z","shell.execute_reply.started":"2022-03-03T15:19:04.699677Z","shell.execute_reply":"2022-03-03T15:19:04.706725Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"In case we had multiple GPU then we can distribute the load among the GPUs","metadata":{}},{"cell_type":"code","source":"net.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:19:12.785081Z","iopub.execute_input":"2022-03-03T15:19:12.785963Z","iopub.status.idle":"2022-03-03T15:19:15.801260Z","shell.execute_reply.started":"2022-03-03T15:19:12.785917Z","shell.execute_reply":"2022-03-03T15:19:15.800547Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Defining a forward pass function which accounts for both accuracy and loss during training phase\ndef fwd_pass(X,y,train=False):\n    if train:\n        net.zero_grad()\n    outputs=net(X)\n    matches=[torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs,y)]\n    acc=matches.count(True)/len(matches)\n    loss=loss_function(outputs,y)\n        \n    if train:\n        loss.backward()\n        optimizer.step()\n    return acc,loss","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:34:23.001673Z","iopub.execute_input":"2022-03-03T15:34:23.002546Z","iopub.status.idle":"2022-03-03T15:34:23.010011Z","shell.execute_reply.started":"2022-03-03T15:34:23.002494Z","shell.execute_reply":"2022-03-03T15:34:23.008966Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Defining a test function to account the validation loss and validation accuracy\ndef test(size=32):\n    \n    random_start=np.random.randint(len(val_x)-size)\n    X,y=val_x[random_start:random_start+size],val_y[random_start:random_start+size]\n    with torch.no_grad():\n        val_acc, val_loss = fwd_pass(X.view(-1,1,50,50).to(device),y.to(device))\n    return val_acc, val_loss\n\nval_acc, val_loss =test(size=400)\nprint(val_acc,val_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:57:42.981009Z","iopub.execute_input":"2022-03-03T15:57:42.981264Z","iopub.status.idle":"2022-03-03T15:57:48.476766Z","shell.execute_reply.started":"2022-03-03T15:57:42.981234Z","shell.execute_reply":"2022-03-03T15:57:48.475984Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import time\n\nMODEL_NAME = f'model{int(time.time())}'\n\nnet=Net().to(device)\noptimizer=optim.Adam(net.parameters(),lr=0.001)\nloss_function=nn.MSELoss()\n\nprint(MODEL_NAME)\n\ndef train():\n    batch_size = 100\n    epochs=15\n    with open('model.log','a') as f:\n        for epoch in range(epochs):\n            for i in tqdm(range(0,len(train_X),batch_size)):\n                batch_X=train_X[i:i+batch_size].view(-1,1,50,50).to(device)\n                batch_y=train_y[i:i+batch_size].to(device)\n                \n                acc,loss=fwd_pass(batch_X,batch_y,train=True)\n                if i % 50 == 0:\n                    val_acc,val_loss=test(size=100)\n                    f.write(f'{MODEL_NAME},{round(time.time(),3)},{epoch},{round(float(acc),2)},{round(float(loss),4)},{round(float(val_acc),2)},{round(float(val_loss),4)}\\n')\n                    \ntrain()","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:47:36.699115Z","iopub.execute_input":"2022-03-03T16:47:36.699877Z","iopub.status.idle":"2022-03-03T16:47:56.412397Z","shell.execute_reply.started":"2022-03-03T16:47:36.699830Z","shell.execute_reply":"2022-03-03T16:47:56.411724Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"#Visualization of training and validation losses and accuracies respectively\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\n\nstyle.use('ggplot')\n\nmodel_name=MODEL_NAME\n\ndef create_acc_loss_graph(model_name):\n    contents = open('model.log','r').read().split('\\n')\n    \n    times=[]\n    accuracies=[]\n    losses=[]\n    \n    val_accs=[]\n    val_losses=[]\n    \n    for c in contents:\n        if model_name in c:\n            name, timestamp, epoch, acc, loss, val_acc, val_loss = c.split(',')\n            \n            times.append(float(timestamp))\n            accuracies.append(float(acc))\n            losses.append(float(loss))\n            val_accs.append(float(val_acc))\n            val_losses.append(float(val_loss))\n            \n    fig=plt.figure(figsize=(10,6))\n    \n    ax1=plt.subplot2grid((2,1),(0,0))\n    ax2=plt.subplot2grid((2,1),(1,0),sharex=ax1)\n    \n    ax1.plot(times, accuracies, label='acc')\n    ax1.plot(times, val_accs, label='val_acc')\n    ax1.legend(loc=2)\n    \n    ax2.plot(times, losses, label='loss')\n    ax2.plot(times, val_losses, label='val_loss')\n    ax2.legend(loc=2)\n    \n    plt.show()\n    \ncreate_acc_loss_graph(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:48:20.853539Z","iopub.execute_input":"2022-03-03T16:48:20.854271Z","iopub.status.idle":"2022-03-03T16:48:21.186235Z","shell.execute_reply.started":"2022-03-03T16:48:20.854212Z","shell.execute_reply":"2022-03-03T16:48:21.185548Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#Train the model on GPU\ndef train(net):\n    \n    epoch=10\n    optimizer=optim.Adam(net.parameters(),lr=0.001)\n    loss_function=nn.MSELoss()\n    \n    for epoch in range(epoch):\n        for i in tqdm(range(0,len(train_X),batch_size)):\n            #print(i,i+batch_size)\n            batch_X=train_X[i:i+batch_size].view(-1,1,50,50).to(device)\n            batch_y=train_y[i:i+batch_size].to(device)\n            \n            net.zero_grad()    #if we are combining multiple network then we might use optimizer.zero_grad as there will be mulitple optimizer\n            outputs=net(batch_X)\n            loss=loss_function(outputs,batch_y)\n            loss.backward()\n            optimizer.step()\n        print(f'Epoch:{epoch},loss: {loss}')","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:53:34.6632Z","iopub.execute_input":"2022-03-02T16:53:34.66346Z","iopub.status.idle":"2022-03-02T16:53:34.670374Z","shell.execute_reply.started":"2022-03-02T16:53:34.663431Z","shell.execute_reply":"2022-03-02T16:53:34.669622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(net)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:53:40.752103Z","iopub.execute_input":"2022-03-02T16:53:40.752355Z","iopub.status.idle":"2022-03-02T16:53:45.177621Z","shell.execute_reply.started":"2022-03-02T16:53:40.752325Z","shell.execute_reply":"2022-03-02T16:53:45.175331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run the test set on GPU\ndef test(net):\n    \n    correct=0\n    total=0\n    \n    with torch.no_grad():\n        for i in tqdm(range(len(val_x))):\n            real_class=torch.argmax(val_y[i]).to(device)\n            net_out=net(val_x[i].view(-1,1,50,50).to(device))[0]\n            predicted_class=torch.argmax(net_out)\n            if real_class == predicted_class:\n                correct+=1\n            total+=1\n    print('Accuracy:',round(correct/total,3))","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:53:51.388091Z","iopub.execute_input":"2022-03-02T16:53:51.388614Z","iopub.status.idle":"2022-03-02T16:53:51.394901Z","shell.execute_reply.started":"2022-03-02T16:53:51.388577Z","shell.execute_reply":"2022-03-02T16:53:51.394187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test(net)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:53:57.585301Z","iopub.execute_input":"2022-03-02T16:53:57.58558Z","iopub.status.idle":"2022-03-02T16:53:58.134655Z","shell.execute_reply.started":"2022-03-02T16:53:57.585549Z","shell.execute_reply":"2022-03-02T16:53:58.133144Z"},"trusted":true},"execution_count":null,"outputs":[]}]}